{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epoch-by-epoch Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import project_config as config\n",
    "from utils.sleep_wake_filter import filter_sleep_series\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from utils.data_utils import read_sleep_dairies_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_sources_path = 'Results/merged_indicators'\n",
    "label = 'AWS Sleep'\n",
    "models = ['pred_PSG-CNN', 'Biobank Sleep']\n",
    "sleep_diaries_path = 'data/Sleep diaries'\n",
    "diaries_df = read_sleep_dairies_v2(sleep_diaries_path, include_naps=False)\n",
    "\n",
    "results = pd.DataFrame()\n",
    "all_preds = pd.DataFrame()\n",
    "for id in config['subject_ids']:\n",
    "\n",
    "    subject_diary = diaries_df[diaries_df['subject_id'] == id]\n",
    "\n",
    "    preds_df = pd.read_csv(f'{merged_sources_path}/sub_{id:02d}.csv')\n",
    "    preds_df['epoch_ts'] = pd.to_datetime(preds_df['epoch_ts'])\n",
    "    # df = df.dropna(subset=[label] + models)  # Drop epochs without a label or prediction\n",
    "    preds_df.insert(0, 'subject_id', id)\n",
    "    \n",
    "    # df['pred_AWS-CNN'] = filter_sleep_series(df['pred_AWS-CNN'])\n",
    "    # df['pred_PSG-CNN'] = filter_sleep_series(df['pred_PSG-CNN'])\n",
    "    \n",
    "    # Here we mark the epochs between sleep start and sleep end as recorded in sleep diary\n",
    "    # This is how it's done:\n",
    "    # - Create a column that's =1 for sleep_start epochs\n",
    "    # - Create a column that's =-1 for sleep_end epochs\n",
    "    # - Combine the two column so that the new \"lights_off_period\" column has a 1 when sleep start and a -1 when it ends\n",
    "    # - Then find the cumulative sum of the lights_off_period column. The cumsum will be 1 between sleep start and sleep end\n",
    "    #     and 0 elsewhere\n",
    "    preds_df['lights_off_time'] = preds_df['epoch_ts'].isin(subject_diary['lights_off']).astype(int)\n",
    "    preds_df['lights_on_time'] = preds_df['epoch_ts'].isin(subject_diary['lights_on']).astype(int).map({0: 0, 1: -1})  # Mark end of sleep with -1\n",
    "    \n",
    "    # merge the two columns. We can simply add them, because they are never non-zero on the same row. i.e. start timestamp and end timestamp are never the same\n",
    "    preds_df['lights_off_period'] = preds_df['lights_off_time'] + preds_df['lights_on_time']\n",
    "    preds_df['lights_off_period'] = preds_df['lights_off_period'].cumsum()\n",
    "\n",
    "    # Next, create a column that assigns a distinct id to each sleep episode\n",
    "    preds_df['sleep_episode_counter'] = preds_df['lights_off_time'].cumsum()  # This is a helper variable that creates a new id evey time sleep starts\n",
    "    preds_df['sleep_episode_id'] = preds_df['sleep_episode_counter'].where(preds_df['lights_off_period'] == 1, 0)\n",
    "\n",
    "    preds_df = preds_df.drop(columns=['lights_off_time', 'lights_on_time', 'sleep_episode_counter'])\n",
    "\n",
    "    all_preds = pd.concat([all_preds, preds_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics computed over CV epochs only\n",
    "from sklearn.metrics import classification_report\n",
    "temp_df = all_preds.copy()\n",
    "temp_df = all_preds[all_preds['lights_off_period'] == 1]\n",
    "# temp_df = temp_df.dropna(subset=['PSG Sleep', 'Biobank Sleep'])\n",
    "temp_df = temp_df.dropna(subset=['AWS Sleep', 'Biobank Sleep', 'pred_PSG-CNN'])\n",
    "temp_df = temp_df[temp_df['is_cv_prediction'] == 1]\n",
    "\n",
    "print('Models tested on Lab-day PSG labels')\n",
    "print('*'*60)\n",
    "print('\\nCNN Model')\n",
    "print(classification_report(y_true=temp_df['PSG Sleep'], y_pred=temp_df['pred_PSG-CNN']))\n",
    "print('-'*60)\n",
    "print('\\nBiobank')\n",
    "print(classification_report(y_true=temp_df['PSG Sleep'], y_pred=temp_df['Biobank Sleep']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "# light_off_preds = all_preds[all_preds['lights_off_period'] == 1]\n",
    "# # temp_df = light_off_preds.dropna(subset=['PSG Sleep', 'Biobank Sleep'])\n",
    "# temp_df = light_off_preds.dropna(subset=['AWS Sleep', 'Biobank Sleep', 'pred_AWS-CNN'])\n",
    "\n",
    "# print('AWS Model')\n",
    "# print(classification_report(y_true=temp_df['AWS Sleep'], y_pred=temp_df['pred_AWS-CNN']))\n",
    "# print('Biobank')\n",
    "# print(classification_report(y_true=temp_df['AWS Sleep'], y_pred=temp_df['Biobank Sleep']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sleep Summary Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sleep_summary_metrics(preds_df, source_col_name):\n",
    "    raise NotImplementedError (\"Use v2\")\n",
    "    # Sleep quality metrics are only calculated during a certain window\n",
    "    # See cells above where this column was created\n",
    "    lights_off_fltr = (preds_df['lights_off_period'] == 1)\n",
    "\n",
    "    # # # # # # # # # # # # # # # # # # # # \n",
    "    # #   TRT: Total Recording Time\n",
    "    # #   Defined as the time in minutes from lights out to\n",
    "    # #   lights on. This time constitutes the sleep opportunity period.\n",
    "    # #   Epochs of sleep are only scored between these two points.\n",
    "    # # # # # # # # # # # # # # # # # # # # \n",
    "\n",
    "    TRT_df = preds_df[lights_off_fltr].groupby(['subject_id', 'sleep_episode_id'])['epoch_ts'].count() / 2\n",
    "    TRT_df = TRT_df.reset_index().rename({'epoch_ts': 'TRT (Min)'}, axis=1)\n",
    "\n",
    "    # # # # # # # # # # # # # # # # # # # # \n",
    "    # #   TST: Total Sleep Time\n",
    "    # #   Defined as the time in minutes scored as NREM or REM\n",
    "    # #   but excluding epochs of Unsure and Wake within the period between lights off and lights on\n",
    "    # # # # # # # # # # # # # # # # # # # # \n",
    "\n",
    "    TST_df = preds_df[lights_off_fltr].groupby(['subject_id', 'sleep_episode_id'])[source_col_name].sum() / 2  # each epoch is half a minute\n",
    "    TST_df = TST_df.reset_index().rename({source_col_name: 'TST (Min)'}, axis=1)\n",
    "\n",
    "    # # # # # # # # # # # # # # # # # # # # \n",
    "    # #   SOL: Sleep Onset Latency\n",
    "    # #   Defined as the time in minutes occurring from lights off to the first epoch of NREM or REM\n",
    "    # # # # # # # # # # # # # # # # # # # # \n",
    "\n",
    "    lights_off_df = preds_df[lights_off_fltr].groupby(['subject_id', 'sleep_episode_id'])['epoch_ts'].min().\\\n",
    "        reset_index().rename({'epoch_ts': 'lights_off_time'}, axis=1)\n",
    "\n",
    "    transition_col = f'{source_col_name} transition'\n",
    "    preds_df[transition_col] = preds_df.groupby(['subject_id', 'sleep_episode_id'])[source_col_name].diff()\n",
    "\n",
    "    falling_asleep_fltr = (preds_df[transition_col] == 1)\n",
    "    # find the first epoch after lights_off_period, when we transition from wake to sleep\n",
    "    sleep_onset_df = preds_df[lights_off_fltr & falling_asleep_fltr].groupby(['subject_id', 'sleep_episode_id'])['epoch_ts'].min().\\\n",
    "        reset_index().rename({'epoch_ts': 'sleep_onset'}, axis=1)\n",
    "\n",
    "    SOL_df = pd.merge(\n",
    "        left=lights_off_df,\n",
    "        right=sleep_onset_df,\n",
    "        on=['subject_id', 'sleep_episode_id'],\n",
    "        how='left'\n",
    "    )\n",
    "    SOL_df['SOL (Min)'] = (SOL_df['sleep_onset'] - SOL_df['lights_off_time']).dt.seconds / 60  # convert to minutes\n",
    "    SOL_df = SOL_df.drop(['lights_off_time'], axis=1)  # keep sleep_onset for WASO\n",
    "\n",
    "    # # # # # # # # # # # # # # # # # # # # \n",
    "    # #   WASO: Wake After Sleep Onset\n",
    "    # # # # # # # # # # # # # # # # # # # # \n",
    "\n",
    "    # We need to find first wake after sleep onset. Let's first remove epochs before sleep onset\n",
    "    first_wake_df = pd.merge(\n",
    "        left=preds_df[lights_off_fltr],\n",
    "        right=SOL_df.drop('SOL (Min)', axis=1),  # don't need this column\n",
    "        on=['subject_id', 'sleep_episode_id'],\n",
    "        how='left'\n",
    "    )\n",
    "    # Sleep onset column is specific to each subject and sleep episode\n",
    "    # So, we don't need to worry about grouping or filtering by these here\n",
    "    # This is a row-wise comparison\n",
    "    first_wake_df = first_wake_df[first_wake_df['epoch_ts'] > first_wake_df['sleep_onset']]  # remove epochs that occur before sleep onset\n",
    "    first_wake_df = first_wake_df[first_wake_df[transition_col] == -1].groupby(['subject_id', 'sleep_episode_id'])['epoch_ts'].min().\\\n",
    "        reset_index().rename({'epoch_ts': 'first_wake'}, axis=1)\n",
    "\n",
    "    # bring in sleep onset timestamp to calculate time between sleep onset and first wake\n",
    "    WASO_df = pd.merge(\n",
    "        left=first_wake_df,\n",
    "        right=sleep_onset_df,\n",
    "        on=['subject_id', 'sleep_episode_id'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    WASO_df['WASO (Min)'] = (WASO_df['first_wake'] - WASO_df['sleep_onset']).dt.seconds / 60  # convert to mintues\n",
    "    WASO_df = WASO_df.drop(['first_wake', 'sleep_onset'], axis=1)\n",
    "\n",
    "    # Now that we're done with WASO we can drop sleep_onset from SOL\n",
    "    SOL_df = SOL_df.drop('sleep_onset', axis=1)\n",
    "\n",
    "    # # # # # # # # # # # # # # # # # # # # \n",
    "    # #   SEEF: Sleep Efficiency\n",
    "    # #   Defined as the percentage of TST against TRT\n",
    "    # # # # # # # # # # # # # # # # # # # # \n",
    "\n",
    "    SEEF_df = pd.merge(\n",
    "        left=TRT_df,\n",
    "        right=TST_df,\n",
    "        on=['subject_id', 'sleep_episode_id'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    SEEF_df['SEEF'] = SEEF_df['TST (Min)'] / SEEF_df['TRT (Min)']\n",
    "    SEEF_df = SEEF_df.drop(['TRT (Min)', 'TST (Min)'], axis=1)\n",
    "    \n",
    "    metrics_list = [TRT_df, TST_df, SEEF_df, SOL_df, WASO_df]\n",
    "\n",
    "    merge_fn = lambda l, r: pd.merge(\n",
    "        left=l,\n",
    "        right=r,\n",
    "        on=['subject_id', 'sleep_episode_id'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    sleep_summary_metrics = reduce(merge_fn, metrics_list)\n",
    "\n",
    "    return sleep_summary_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sleep_summary_metrics_v2(preds_df, source_col_name):\n",
    "    \n",
    "    # # # \n",
    "    # This v2 function calculates SOL and WASO in a different way\n",
    "    # Instead of looking for a transition to sleep (wake for WASO)\n",
    "    # It simply takes the first lights_off_period sleep epoch as sleep onset\n",
    "    # And the first wake epoch after sleep onset as first-wake\n",
    "    # This probably won't affect WASO, but will certainly change SOL\n",
    "    # It changes SOL because in many cases the very first epoch of the\n",
    "    # lights_off_period window is already a sleep epoch and there is no transition\n",
    "    # inside the lights_off_period window\n",
    "\n",
    "    # Sleep quality metrics are only calculated during a certain window\n",
    "    # See cells above where this column was created\n",
    "    lights_off_fltr = (preds_df['lights_off_period'] == 1)\n",
    "\n",
    "    # # # # # # # # # # # # # # # # # # # # \n",
    "    # #   TRT: Total Recording Time\n",
    "    # #   Defined as the time in minutes from lights out to\n",
    "    # #   lights on. This time constitutes the sleep opportunity period.\n",
    "    # #   Epochs of sleep are only scored between these two points.\n",
    "    # # # # # # # # # # # # # # # # # # # # \n",
    "\n",
    "    TRT_df = preds_df[lights_off_fltr].groupby(['subject_id', 'sleep_episode_id'])['epoch_ts'].count() / 2\n",
    "    TRT_df = TRT_df.reset_index().rename({'epoch_ts': 'TRT (Min)'}, axis=1)\n",
    "\n",
    "    # # # # # # # # # # # # # # # # # # # # \n",
    "    # #   TST: Total Sleep Time\n",
    "    # #   Defined as the time in minutes scored as NREM or REM\n",
    "    # #   but excluding epochs of Unsure and Wake within the period between lights off and lights on\n",
    "    # # # # # # # # # # # # # # # # # # # # \n",
    "\n",
    "    TST_df = preds_df[lights_off_fltr].groupby(['subject_id', 'sleep_episode_id'])[source_col_name].sum() / 2  # each epoch is half a minute\n",
    "    TST_df = TST_df.reset_index().rename({source_col_name: 'TST (Min)'}, axis=1)\n",
    "\n",
    "    # # # # # # # # # # # # # # # # # # # # \n",
    "    # #   SOL: Sleep Onset Latency\n",
    "    # #   Defined as the time in minutes occurring from lights off to the first epoch of NREM or REM\n",
    "    # # # # # # # # # # # # # # # # # # # # \n",
    "\n",
    "    lights_off_df = preds_df[lights_off_fltr].groupby(['subject_id', 'sleep_episode_id'])['epoch_ts'].min().\\\n",
    "        reset_index().rename({'epoch_ts': 'lights_off_time'}, axis=1)  # timestamp of the first lights_off_period epoch\n",
    "\n",
    "    asleep_fltr = (preds_df[source_col_name] == 1)\n",
    "    sleep_onset_df = preds_df[lights_off_fltr & asleep_fltr].groupby(['subject_id', 'sleep_episode_id'])['epoch_ts'].min().\\\n",
    "        reset_index().rename({'epoch_ts': 'sleep_onset'}, axis=1)  # timestamp of the first lights_off_period sleep epoch\n",
    "\n",
    "    SOL_df = pd.merge(\n",
    "        left=lights_off_df,\n",
    "        right=sleep_onset_df,\n",
    "        on=['subject_id', 'sleep_episode_id'],\n",
    "        how='left'\n",
    "    )\n",
    "    SOL_df['SOL (Min)'] = (SOL_df['sleep_onset'] - SOL_df['lights_off_time']).dt.seconds / 60  # convert to minutes\n",
    "    SOL_df = SOL_df.drop(['lights_off_time'], axis=1)  # keep sleep_onset for WASO\n",
    "\n",
    "    # # # # # # # # # # # # # # # # # # # # \n",
    "    # #   WASO: Wake After Sleep Onset\n",
    "    # #   Defined as the time in minutes of epochs scored as wake from SOL until lights on\n",
    "    # # # # # # # # # # # # # # # # # # # # \n",
    "\n",
    "    # We need to find first wake after sleep onset. Let's first remove epochs before sleep onset\n",
    "    first_wake_df = pd.merge(  # bringing in sleep onset (binary indicator) column\n",
    "        left=preds_df[lights_off_fltr],\n",
    "        right=SOL_df.drop('SOL (Min)', axis=1),  # don't need this column\n",
    "        on=['subject_id', 'sleep_episode_id'],\n",
    "        how='left'\n",
    "    )\n",
    "    # Sleep onset column is specific to each subject and sleep episode\n",
    "    # So, we don't need to worry about grouping or filtering by these here\n",
    "    # This is a row-wise comparison\n",
    "    after_sleep_onset_df = first_wake_df[first_wake_df['epoch_ts'] > first_wake_df['sleep_onset']]  # remove epochs that occur before sleep onset\n",
    "    awake_fltr = (after_sleep_onset_df[source_col_name] == 0)\n",
    "    WASO_df = after_sleep_onset_df[awake_fltr].groupby(['subject_id', 'sleep_episode_id'])['epoch_ts'].count() / 2  # 2 epochs = 1 minutes\n",
    "    WASO_df = WASO_df.reset_index().rename({'epoch_ts': 'WASO (Min)'}, axis=1)\n",
    "\n",
    "    # bring in sleep onset timestamp to calculate time between sleep onset and first wake\n",
    "    # WASO_df = pd.merge(\n",
    "    #     left=first_wake_df,\n",
    "    #     right=sleep_onset_df,\n",
    "    #     on=['subject_id', 'sleep_episode_id'],\n",
    "    #     how='left'\n",
    "    # )\n",
    "\n",
    "    # WASO_df['WASO (Min)'] = (WASO_df['first_wake'] - WASO_df['sleep_onset']).dt.seconds / 60  # convert to mintues\n",
    "    # WASO_df = WASO_df.drop(['first_wake', 'sleep_onset'], axis=1)\n",
    "\n",
    "    # Now that we're done with WASO we can drop sleep_onset from SOL\n",
    "    SOL_df = SOL_df.drop('sleep_onset', axis=1)\n",
    "\n",
    "    # # # # # # # # # # # # # # # # # # # # \n",
    "    # #   SEEF: Sleep Efficiency\n",
    "    # #   Defined as the percentage of TST against TRT\n",
    "    # # # # # # # # # # # # # # # # # # # # \n",
    "\n",
    "    SEEF_df = pd.merge(\n",
    "        left=TRT_df,\n",
    "        right=TST_df,\n",
    "        on=['subject_id', 'sleep_episode_id'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    SEEF_df['SEEF'] = SEEF_df['TST (Min)'] / SEEF_df['TRT (Min)']\n",
    "    SEEF_df = SEEF_df.drop(['TRT (Min)', 'TST (Min)'], axis=1)\n",
    "    \n",
    "    metrics_list = [TRT_df, TST_df, SEEF_df, SOL_df, WASO_df]\n",
    "\n",
    "    merge_fn = lambda l, r: pd.merge(\n",
    "        left=l,\n",
    "        right=r,\n",
    "        on=['subject_id', 'sleep_episode_id'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    sleep_summary_metrics = reduce(merge_fn, metrics_list)\n",
    "\n",
    "    return sleep_summary_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load participation dates to find the lab-day\n",
    "# The lab-day is the last day for all subjects\n",
    "# So we can find the time that lab day starts by subtracting 1 Day (exactly 24 hours)\n",
    "# from their end timestamp\n",
    "\n",
    "# We need to remove lab day from metric calculations (at least for now)\n",
    "# Becuase we don't have proper predictions for lab day (used for training)\n",
    "# there are rare cases where a few epochs were not in training and so they appear in the test set\n",
    "# And not removing them could bias our metric values\n",
    "# So, I explicitly remove the entire lab day before calculating sleep summary metrics\n",
    "\n",
    "participation_dates = pd.read_csv('data/participation_dates.csv')\n",
    "\n",
    "for dt_col in ['start_timestamp', 'end_timestamp']:\n",
    "    participation_dates[dt_col] = pd.to_datetime(participation_dates[dt_col])\n",
    "\n",
    "participation_dates['lab_day_start'] = pd.to_datetime(participation_dates['end_timestamp'])\n",
    "participation_dates['lab_day_start'] = participation_dates['end_timestamp'] - np.timedelta64(1, 'D')\n",
    "participation_dates = participation_dates[['subject_id', 'start_timestamp', 'lab_day_start']]\n",
    "\n",
    "# Remove epochs after the timestamp that marks the start of the lab day\n",
    "# See comment above\n",
    "preds_df = pd.merge(\n",
    "    left=all_preds,\n",
    "    right=participation_dates,\n",
    "    on='subject_id',\n",
    "    how='left'\n",
    ")\n",
    "valid_data_fltr = (preds_df['epoch_ts'].between(preds_df['start_timestamp'], preds_df['lab_day_start'], inclusive='left'))\n",
    "preds_df = preds_df[valid_data_fltr].drop('lab_day_start', axis=1)\n",
    "\n",
    "# Now calculating the metrics\n",
    "source_cols = ['pred_PSG-CNN', 'Biobank Sleep', 'AWS Sleep']\n",
    "metrics_df = pd.DataFrame()\n",
    "for source in source_cols:\n",
    "    # source_metrics_df = calculate_sleep_summary_metrics(preds_df, source_col_name=source)\n",
    "    source_metrics_df = calculate_sleep_summary_metrics_v2(preds_df, source_col_name=source)\n",
    "    # for col in [c for c in source_metrics_df.columns if c not in ['subject_id', 'sleep_episode_id']]:\n",
    "    #     source_metrics_df = source_metrics_df.rename({col: col + f'-{source}'}, axis=1)\n",
    "    source_metrics_df.insert(0, 'source', source)\n",
    "    metrics_df = pd.concat([metrics_df, source_metrics_df])\n",
    "\n",
    "# metrics_df.to_excel('sleep_metrics.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.drop(['subject_id', 'sleep_episode_id'], axis=1).groupby('source').agg(['mean', 'std']).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # preds_df.groupby('sleep_episode_id')['Biobank Sleep'].transform(lambda x: x.isna().sum())\n",
    "# temp = preds_df[preds_df['sleep_episode_id'] > 0].copy()\n",
    "# temp['biobank_nan'] = temp['Biobank Sleep'].isna()\n",
    "# temp['episode_has_nan'] = temp.groupby(['subject_id', 'sleep_episode_id'])['biobank_nan'].transform('sum').gt(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = temp[~temp['episode_has_nan']]\n",
    "\n",
    "# # Now calculating the metrics\n",
    "# source_cols = ['pred_PSG-CNN', 'Biobank Sleep', 'AWS Sleep']\n",
    "# metrics_df = pd.DataFrame()\n",
    "# for source in source_cols:\n",
    "#     source_metrics_df = calculate_sleep_summary_metrics(temp, source_col_name=source)\n",
    "#     source_metrics_df.insert(0, 'source', source)\n",
    "#     metrics_df = pd.concat([metrics_df, source_metrics_df])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
